{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost minimalize 심화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost / loss function\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize : Gradient Descent using derivative: W -= Learning_rate * derivative\n",
    "\n",
    "# 경사하강 알고리즘을 수동으로 작성해줌.\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) # Cost 미분\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "\n",
    "# Minimize : Gradient Descent Magic\n",
    "# optimizer = tf.train.GradientDescentOptimizer(leaerning_rate=0.1)\n",
    "# train = optimizer.minimize(cost)\n",
    "# 미분할 식이 복잡할 때  위의 코드를 이용하면 자동적으로 미분해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.788912 [-0.06196964]\n",
      "1 4.491069 [0.4336162]\n",
      "2 1.2774593 [0.69792867]\n",
      "3 0.36336607 [0.8388953]\n",
      "4 0.10335742 [0.9140775]\n",
      "5 0.029399432 [0.9541747]\n",
      "6 0.008362489 [0.97555983]\n",
      "7 0.0023786654 [0.98696524]\n",
      "8 0.0006766012 [0.99304813]\n",
      "9 0.0001924531 [0.99629235]\n",
      "10 5.4739965e-05 [0.9980226]\n",
      "11 1.557047e-05 [0.9989454]\n",
      "12 4.428576e-06 [0.9994376]\n",
      "13 1.2600248e-06 [0.9997]\n",
      "14 3.5830533e-07 [0.99984]\n",
      "15 1.01821016e-07 [0.9999147]\n",
      "16 2.8939656e-08 [0.9999545]\n",
      "17 8.230376e-09 [0.99997574]\n",
      "18 2.3467415e-09 [0.99998707]\n",
      "19 6.692744e-10 [0.9999931]\n",
      "20 1.8856383e-10 [0.9999963]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict = {X: x_data, Y:y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
